apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    component: alertmanager
  name: prometheus-alertmanager
  namespace: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    component: kube-state-metrics
  name: prometheus-kube-state-metrics
  namespace: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    component: node-exporter
  name: prometheus-node-exporter
  namespace: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    component: server
  name: prometheus-server
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: prometheus
    component: kube-state-metrics
  name: prometheus-kube-state-metrics
  namespace: monitoring
rules:
- apiGroups:
  - certificates.k8s.io
  resources:
  - certificatesigningrequests
  verbs:
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  - volumeattachments
  verbs:
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  - networkpolicies
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  - nodes
  - persistentvolumeclaims
  - pods
  - services
  - resourcequotas
  - replicationcontrollers
  - limitranges
  - persistentvolumeclaims
  - persistentvolumes
  - endpoints
  - secrets
  - configmaps
  - volumeattachments
  verbs:
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - daemonsets
  - deployments
  - replicasets
  - ingresses
  verbs:
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - statefulsets
  - daemonsets
  - deployments
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - cronjobs
  - jobs
  verbs:
  - list
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - list
  - watch
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - list
  - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: prometheus
    component: server
  name: prometheus-server
  namespace: monitoring
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  - ingresses
  - configmaps
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - ingresses/status
  - ingresses
  verbs:
  - get
  - list
  - watch
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: prometheus
    component: kube-state-metrics
  name: prometheus-kube-state-metrics
  namespace: monitoring
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-kube-state-metrics
subjects:
- kind: ServiceAccount
  name: prometheus-kube-state-metrics
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: prometheus
    component: server
  name: prometheus-server
  namespace: monitoring
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-server
subjects:
- kind: ServiceAccount
  name: prometheus-server
  namespace: monitoring
---
apiVersion: v1
data:
  alertmanager.yml: |
    global:
    receivers:
    - name: Nodos
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#Alertas"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
             *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
            *Description:* {{ .Annotations.description }}
            *Details:*
            {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
            {{ end }}
           {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'

    - name: NodosCritical
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#Alertas"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
             *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
              *Description:* {{ .Annotations.description }}
              *Details:*
              {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
              {{ end }}
             {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/ProductionAlerts
          send_resolved: true

    - name: Postventa
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#postventa-alert"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
            *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
            *Description:* {{ .Annotations.description }}
            *Details:*
             {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
             {{ end }}
            {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/PostventaAlerts
          send_resolved: true

    - name: Shopping
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#shopping-monitoring"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
            *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
            *Description:* {{ .Annotations.description }}
            *Details:*
             {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
             {{ end }}
            {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/ShoppingAlerts
          send_resolved: true

    - name: Marketplace
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#marketplace-monitoring"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
             *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
             *Description:* {{ .Annotations.description }}
             *Details:*
             {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
             {{ end }}
             {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/MarketplaceAlerts
          send_resolved: true

    - name: Pricing
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#pricing-monitoring"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
             *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
             *Description:* {{ .Annotations.description }}
             *Details:*
             {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
             {{ end }}
             {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/PricingAlerts
          send_resolved: true

    - name: Ccm
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#ccm-alerts"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
             *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
             *Description:* {{ .Annotations.description }}
             *Details:*
             {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
             {{ end }}
             {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/CcmAlerts
          send_resolved: true

    - name: Adn
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/z9b14w5tfp8f9mmd79ob58iuhe'
        channel: "#adn-alertas-tech"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
             *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
             *Description:* {{ .Annotations.description }}
             *Details:*
             {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
             {{ end }}
             {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/AdnAlerts
          send_resolved: true

    - name: Impuestos
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#impuestos-alerts"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
           *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
           *Description:* {{ .Annotations.description }}
           *Details:*
           {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
           {{ end }}
           {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/ImpuestosAlerts
          send_resolved: true

    - name: Logistics
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#oslo-alerts"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
          *Description:* {{ .Annotations.description }}
          *Details:*
           {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
           {{ end }}
           {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/LogisticsAlerts
          send_resolved: true

    - name: Ipos
      slack_configs:
      - send_resolved: true
        api_url: 'https://mattermost.management.fravega.com/hooks/mu4ruryuf3ddpp44y1fo6t895r'
        channel: "#ipos-alerts"
        title: '{{ template "slack.default.title" . }}'
        text: |-
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
          *Description:* {{ .Annotations.description }}
          *Details:*
           {{ range .Labels.SortedPairs }} • *{{ .Name }}:* `{{ .Value }}`
           {{ end }}
           {{ end }}
        fallback: '{{ template "slack.default.fallback" . }}'
        icon_emoji: '{{ template "slack.default.iconemoji" . }}'
        icon_url: '{{ template "slack.default.iconurl" . }}'
      webhook_configs:
        - url: http://prom-sns-alerts:8080/v1/send/IposAlerts
          send_resolved: true

    route:
      receiver: 'Nodos'
      group_interval: 1m
      group_wait: 10s
      repeat_interval: 5m
      routes:
        - match:
            severity: postventacritical
          receiver: Postventa
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: shoppingcritical
          receiver: Shopping
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: marketplacecritical
          receiver: Marketplace
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: pricingcritical
          receiver: Pricing
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: critical
          receiver: NodosCritical
          group_interval: 1m
          group_wait: 1m
          repeat_interval: 1m
        - match:
            severity: ccmcritical
          receiver: Ccm
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: adncritical
          receiver: Adn
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: impuestoscritical
          receiver: Impuestos
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: logisticscritical
          receiver: Logistics
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
        - match:
            severity: iposcritical
          receiver: Ipos
          group_interval: 5m
          group_wait: 5m
          repeat_interval: 5m
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    component: alertmanager
  name: prometheus-alertmanager
  namespace: monitoring
---
apiVersion: v1
data:
  alerts: "groups:\n- name: Nodes\n  rules:\n  - alert: NodeMemory Production\n    annotations:\n
    \     description: '{{ $labels.instance }} of job {{ $labels.job }} the memory
    ram  is in the 80 percentage.'\n      summary: Instance {{ $labels.instance }}
    the memory > 80% percentage.\n    expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes
    - node_memory_Cached_bytes - node_memory_Buffers_bytes ) / node_memory_MemTotal_bytes
    * 100 > 80\n    for: 30s\n    labels:\n      severity: warning\n\n  - alert: NodeCPUused
    Production\n    annotations:\n      description: '{{ $labels.instance }} of job
    {{ $labels.job }} the CPU is use in the 80 \tpercentage .'\n      summary: Instance
    {{ $labels.instance }} the CPU > 80% percentage\n    expr: 100 - (avg by (instance)
    (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)  > 80\n    for: 30s\n
    \   labels:\n      severity: warning\n\n  - alert: DiskWillFillIn4Hours Production\n
    \   annotations:\n      description: '{{ $labels.instance }} of job {{ $labels.job
    }} the  Disk will fill in 4 hours .'\n      summary: Instance {{ $labels.instance
    }} the Disk will fill in 4 hours\n    expr: predict_linear(node_filesystem_free{job=\"node-exporter\"}[1h],
    4 * 3600) < 0\n    for: 5m\n    labels:\n      severity: warning\n\n  - alert:
    NodeLoad1 Production\n    annotations:\n      description: '{{ $labels.instance
    }} of job {{ $labels.job }} the  load of node is on 100 percentage in last 5 minute
    \ .'\n      summary: Instance {{ $labels.instance }} the load of node is on 100
    percentage in last 5 minute\n    expr: sum(node_load1) by (node) / count(node_cpu{mode=\"system\"})
    by (node) * 100 > 100\n    for: 1m\n    labels:\n      severity: warning\n\n  -
    alert: NodeLoad15 Production\n    annotations:\n      description: '{{ $labels.instance
    }} of job {{ $labels.job }} the  load of node is on 100 percentage in last 15
    minute  .'\n      summary: Instance {{ $labels.instance }} the load of node is
    on 100 percentage in last 15 minute\n    expr: sum(node_load15) by (node) / count(node_cpu{mode=\"system\"})
    by (node) * 100 > 100\n    for: 2m\n    labels:\n      severity: critical\n\n
    \ - alert: NodeHighMemory Production\n    annotations:\n      description: '{{
    $labels.instance }} of job {{ $labels.job }} the memory ram  is in the 90 percentage.'\n
    \     summary: Instance {{ $labels.instance }} the memory ram  is in the 90 percentage.\n
    \   expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Cached_bytes
    - node_memory_Buffers_bytes ) / node_memory_MemTotal_bytes * 100 > 90\n    for:
    1m\n    labels:\n      severity: critical\n\n  - alert: NodeisDown Production\n
    \   annotations:\n      description: '{{ $labels.instance }} of job {{ $labels.job
    }} is down!.'\n      summary: Instance {{ $labels.instance }} is down, this is
    critial!.\n    expr: up{component=\"node-exporter\"} == 0\n    for: 30s\n    labels:\n
    \     severity: warning\n\n  - alert: free space < to 10% Production\n    annotations:\n
    \     description: ' {{ $labels.pod }}  without free space in the pvc  {{ $labels.instance
    }} '\n      summary: The {{ $labels.pod }} is without free space in the pvc, this
    is critial!.\n    expr: ((kubelet_volume_stats_available_bytes * 100) / (kubelet_volume_stats_capacity_bytes
    ) ) < 10\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: free
    space < 20 % Production\n    annotations:\n      description: ' {{ $labels.pod
    }}  without free space in the pvc  {{ $labels.instance }} '\n      summary: The
    {{ $labels.pod }} is without free space in the pvc, this is critial!.\n    expr:
    ((kubelet_volume_stats_available_bytes * 100) / (kubelet_volume_stats_capacity_bytes
    ) ) < 20\n    for: 5m\n    labels:\n      severity: warning\n\n  - alert: free
    space < 30 % Production\n    annotations:\n      description: ' without free space
    of  disk in the  {{ $labels.instance }} '\n      summary: without free space of
    \ disk in the  {{ $labels.instance }}.\n    expr:  ((node_filesystem_avail_bytes
    * 100) / node_filesystem_size_bytes) < 30\n    for: 5m\n    labels:\n      severity:
    warning\n\n  - alert: Porcentage of free space < 10 percentage\n    annotations:\n
    \     description: ' without free space of  disk in the  {{ $labels.instance }}
    '\n      summary: without free space of  disk in the  {{ $labels.instance }}.\n
    \   expr:  ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes)
    < 10\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    kube-system Production\n    annotations:\n      description: ' {{ $labels.pod
    }}  is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"kube-system\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    shared Production\n    annotations:\n      description: ' {{ $labels.pod }}  is
    restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod }}
    is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"shared\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    nlp Production\n    annotations:\n      description: ' {{ $labels.pod }}  is restart!
    on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod }} is restart,
    this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"nlp\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    monitoring Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: (sum(increase(kube_pod_container_status_restarts_total{namespace=\"monitoring\"}[10m]))
    by (container)) > 3\n    for: 30s\n    labels:\n      severity: critical\n\n  -
    alert: Pod restart ingress-nginx Production\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"ingress-nginx\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    ingress-nginx-public Production\n    annotations:\n      description: ' {{ $labels.pod
    }}  is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"ingress-nginx-public\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    logs Production\n    annotations:\n      description: ' {{ $labels.pod }}  is
    restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod }}
    is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"logs\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    security Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"security\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    ambassador Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"ambassador\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: Pod restart
    bookstack Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"bookstack\"}
    > 5\n    for: 30s\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    bookstack Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"bookstack\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    ambassador Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"ambassador\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    monitoring Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"monitoring\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    security Production\n    annotations:\n      description: ' {{ $labels.pod }}
    \ is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"security\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    logs Production\n    annotations:\n      description: ' {{ $labels.pod }}  is
    with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance {{
    $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"logs\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    ingress-nginx-public Production\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"ingress-nginx-public\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    ingress-nginx Production\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"ingress-nginx\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    nlp Production\n    annotations:\n      description: ' {{ $labels.pod }}  is with
    a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"nlp\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n  - alert: PodwithError
    kube-system Production\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"kube-system\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: critical\n\n\n  - alert: ElasticSearchLogs
    Production\n    annotations:\n      description: ' El elasticsearch de logs esta
    RED '\n      summary: El elasticsearch de logs esta RED !.\n    expr: elasticsearch_cluster_health_status{cluster=\"453967355910:logs-prod\",color=\"red\"}
    > 0 OR absent (elasticsearch_cluster_health_status{cluster=\"453967355910:logs-prod\"})\n
    \   for: 1m\n    labels:\n      severity: critical\n\n  - alert: ElasticSearchLogs
    Production\n    annotations:\n      description: ' El elasticsearch de logs esta
    Yellow '\n      summary: El elasticsearch de logs esta yellow !.\n    expr: elasticsearch_cluster_health_status{cluster=\"453967355910:logs-prod\",color=\"yellow\"}
    > 0  OR absent (elasticsearch_cluster_health_status{cluster=\"453967355910:logs-prod\"})\n
    \   for: 1m\n    labels:\n      severity: warning\n\n- name: Shopping\n  rules:\n
    \ - alert: PodRestart ShoppingProd\n    annotations:\n      description: ' {{
    $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"shopping\"}
    > 5\n    for: 5m\n    labels:\n      severity: shoppingcritical\n\n  - alert:
    PodwithError ShoppingProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"shopping\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: shoppingcritical\n\n- name: Marketplace\n
    \ rules:\n  - alert: PodRestart marketplaceProd\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"marketplace\"}
    > 5\n    for: 5m\n    labels:\n      severity: marketplacecritical\n\n  - alert:
    PodwithError marketplaceProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"marketplace\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: marketplacecritical\n\n- name:
    Pricing\n  rules:\n  - alert: PodRestart PricingProd\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"pricing\"}
    > 5\n    for: 5m\n    labels:\n      severity: pricingcritical\n\n  - alert: PodwithError
    PricingProd\n    annotations:\n      description: ' {{ $labels.pod }}  is with
    a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"pricing\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: pricingcritical\n\n- name: Postventa\n
    \ rules:\n  - alert: PodRestart PostventaProd\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"postventa\"}
    > 5\n    for: 5m\n    labels:\n      severity: postventacritical\n\n  - alert:
    PodwithError PostventaProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"postventa\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: postventacritical\n\n  - alert:
    KafkaTopic ec-orderfeed PostventaProd\n    annotations:\n      description: '
    It is topic ec-orderfeed is bellow that 0'\n      summary: ' It is topic ec-orderfeed
    is bellow that 0'\n    expr: sum(delta(kafka_topic_partition_current_offset{topic=~\"ec-orderfeed\"}[5m]))
    < 1 and ON()  hour() > 3 < 23\n    for: 5m\n    labels:\n      severity: postventacritical\n\n
    \ - alert: KafkaTopic oms-event PostventaProd\n    annotations:\n      description:
    ' It is topic oms-eventis bellow that 0'\n      summary: ' It is topic oms-event
    is bellow that 0'\n    expr: sum(delta(kafka_topic_partition_current_offset{topic=~\"oms-event\"}[5m]))
    < 1 and ON()  hour() > 10 < 5\n    for: 5m\n    labels:\n      severity: postventacritical\n\n\n
    \ - alert: KafkaTopic ccm-notification-created-meli PostventaProd\n    annotations:\n
    \     description: ' It is topic ccm-notification-created-meli bellow that 1'\n
    \     summary: ' It is topic ccm-notification-created-meli is bellow that 1'\n
    \   expr: sum(delta(kafka_topic_partition_current_offset{topic=~\"ccm-notification-created-meli\"}[5m]))
    < 1 and ON()  hour() > 10 < 5\n    for: 5m\n    labels:\n      severity: postventacritical\n\n\n-
    name: AdnProduction\n  rules:\n  - alert: PodRestart AdnProd\n    annotations:\n
    \     description: ' {{ $labels.pod }}  is restart! on {{ $labels.instance }}
    '\n      summary: Instance {{ $labels.pod }} is restart, this is critical!.\n
    \   expr: rate(kube_pod_container_status_restarts_total{namespace=\"adn\"}[1h])
    * 3600 > 3\n    for: 5m\n    labels:\n      severity: adncritical\n\n  - alert:
    PodRestart AdnGachiProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: rate(kube_pod_container_status_restarts_total{namespace=\"adn-gachi\"}
    [1h])* 3600 > 3\n    for: 5m\n    labels:\n      severity: adncritical\n\n  -
    alert: PodRestart AdnPachiProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is restart! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is restart, this is critical!.\n    expr: rate(kube_pod_container_status_restarts_total{namespace=\"adn-pachi\"}[1h]
    )* 3600 > 3\n    for: 5m\n    labels:\n      severity: adncritical\n\n  - alert:
    PodwithError AdnPachiProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"adn-pachi\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: adncritical\n\n  - alert: PodwithError
    AdnGachiProd\n    annotations:\n      description: ' {{ $labels.pod }}  is with
    a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"adn-gachi\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: adncritical\n\n  - alert: PodwithError
    AdnProd\n    annotations:\n      description: ' {{ $labels.pod }}  is with a type
    of ERROR! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"adn\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: adncritical\n\n- name: ImpuestosProduction\n
    \ rules:\n  - alert: PodRestart ImpuestosProd\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"impuestos\"}
    > 5\n    for: 5m\n    labels:\n      severity: impuestoscritical\n\n  - alert:
    PodwithError ImpuestosProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"impuestos\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: impuestoscritical\n\n- name: CcmProduction\n
    \ rules:\n  - alert: PodRestart CcmProd\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"ccm\"}
    > 5\n    for: 5m\n    labels:\n      severity: ccmcritical\n\n  - alert: PodwithError
    CcmProd\n    annotations:\n      description: ' {{ $labels.pod }}  is with a type
    of ERROR! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"ccm\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: ccmcritical\n\n- name: Logistics\n
    \ rules:\n  - alert: PodRestart logisticsProd\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"logistics\"}
    > 5\n    for: 5m\n    labels:\n      severity: logisticscritical\n\n  - alert:
    PodwithError logisticsProd\n    annotations:\n      description: ' {{ $labels.pod
    }}  is with a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"logistics\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: logisticscritical\n\n- name: Ipos\n
    \ rules:\n  - alert: PodRestart logisticsProd\n    annotations:\n      description:
    ' {{ $labels.pod }}  is restart! on {{ $labels.instance }} '\n      summary: Instance
    {{ $labels.pod }} is restart, this is critical!.\n    expr: kube_pod_container_status_restarts_total{namespace=\"ipos\"}
    > 5\n    for: 5m\n    labels:\n      severity: iposcritical\n\n  - alert: PodwithError
    logisticsProd\n    annotations:\n      description: ' {{ $labels.pod }}  is with
    a type of ERROR! on {{ $labels.instance }} '\n      summary: Instance {{ $labels.pod
    }} is with a type of ERROR!.\n    expr: sum(rate(kube_pod_container_status_terminated_reason{namespace=\"ipos\",reason!=\"Completed\"}[5m]))
    == 1\n    for: 5m\n    labels:\n      severity: iposcritical\n\n\n- name: ingress\n
    \ rules:\n  - alert: ssl expire < 25 days\n    annotations:\n      description:
    'Ingress {{ $labels.host }}  is ssl experies < 25 day'\n      summary: 'Ingress
    {{ $labels.host }}  is ssl experies < 25 day'\n    expr: avg(nginx_ingress_controller_ssl_expire_time_seconds{ingress=~\".*\"})
    by (host) - time()  < 2160000\n    for: 30s\n    labels:\n      severity: critical\n"
  prometheus.yml: |
    global:
      evaluation_interval: 60s
      scrape_interval: 60s
      scrape_timeout: 30s
      external_labels:
        slave: production
    rule_files:
    - /etc/config/rules
    - /etc/config/alerts
    scrape_configs:

    - job_name: prometheus-production
      scrape_interval: 1m
      static_configs:
      - targets:
        - localhost:9090

    - job_name: blackbox_tcp
      scrape_interval: 10s
      metrics_path: /probe
      params:
        module: [tcp_connect]
      static_configs:
      - targets:
        - ad-fravega.com:389
        - 10.6.3.18:1433
        - lira.adn-gachi:80
        - lira.adn-pachi:80
        - cajareportesui.adn:80

      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter-prometheus-blackbox-exporter:9115 # The blackbox exporter.

    - job_name: fvg_vs_capa
      scrape_interval: 10s
      metrics_path: /probe
      params:
        module: [http_2xx]
      static_configs:
      - targets:
        - https://internal-creditos-personales-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-limites-credito-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-clientes-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-limites-credito-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-carteras-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-rest-saps.stable.production.lorfin.com.ar/actuator/health
        - https://internal-tarjetas-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-rest-saps.stable.production.lorfin.com.ar/actuator/health
        - https://internal-planes-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-sellados-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-financiadores-api.stable.production.lorfin.com.ar/actuator/health
        - https://internal-server-autenticacion.stable.production.lorfin.com.ar/actuator/health
        - https://internal-creditos-personales-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-carteras-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-clientes-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-rest-saps.nr.production.lorfin.com.ar/actuator/health
        - https://internal-tarjetas-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-rest-saps.nr.production.lorfin.com.ar/actuator/health
        - https://internal-planes-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-sellados-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-financiadores-api.nr.production.lorfin.com.ar/actuator/health
        - https://internal-server-autenticacion.nr.production.lorfin.com.ar/actuator/health

      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter-prometheus-blackbox-exporter:9115 # The blackbox exporter.

    - job_name: blackbox_icmp
      metrics_path: /probe
      params:
        module: [icmp_test]
      static_configs:
        - targets:
          - 52.54.255.116
          - 52.204.112.22

      relabel_configs:
       - source_labels: [__address__]
         target_label: __param_target
       - source_labels: [__param_target]
         target_label: instance
       - target_label: __address__
         replacement: blackbox-exporter-prometheus-blackbox-exporter:9115 # The blackbox exporter.

    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-apiservers-production
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: default;kubernetes;https
        source_labels:
        - __meta_kubernetes_namespace
        - __meta_kubernetes_service_name
        - __meta_kubernetes_endpoint_port_name
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes-production
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true

    - job_name: kubernetes-nodes-probes-production
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/probes
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true

    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes-cadvisor-production
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - job_name: kubernetes-service-endpoints-production
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: kubernetes_node
    - honor_labels: true
      job_name: prometheus-pushgateway-production
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - action: keep
        regex: pushgateway
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
    - job_name: kubernetes-services-production
      kubernetes_sd_configs:
      - role: service
      metrics_path: /probe
      params:
        module:
        - http_2xx
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
      - source_labels:
        - __address__
        target_label: __param_target
      - replacement: blackbox-exporter-prometheus-blackbox-exporter:9115
        target_label: __address__
      - source_labels:
        - __param_target
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name

    - job_name: msk-shared-production
      static_configs:
      - targets:
        - b-4.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11001
        - b-3.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11001
        - b-2.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11001
        - b-1.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11001
        - b-4.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11002
        - b-3.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11002
        - b-2.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11002
        - b-1.msk-shared-production.b63ani.c18.kafka.us-east-1.amazonaws.com:11002

    - job_name: kubernetes-pods-production
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: kubernetes_pod_name

    alerting:
      alertmanagers:
      - kubernetes_sd_configs:
          - role: pod
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace]
          regex: monitoring
          action: keep
        - source_labels: [__meta_kubernetes_pod_label_app]
          regex: prometheus
          action: keep
        - source_labels: [__meta_kubernetes_pod_label_component]
          regex: alertmanager
          action: keep
        - source_labels: [__meta_kubernetes_pod_container_port_number]
          regex:
          action: drop
  rules: |
    {}
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    component: server
  name: prometheus-server
  namespace: monitoring
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
    component: alertmanager
  name: prometheus-alertmanager
  namespace: monitoring
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 9093
  selector:
    app: prometheus
    component: alertmanager
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: prometheus
    component: kube-state-metrics
  name: prometheus-kube-state-metrics
  namespace: monitoring
spec:
  clusterIP: None
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app: prometheus
    component: kube-state-metrics
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: prometheus
    component: node-exporter
  name: prometheus-node-exporter
  namespace: monitoring
spec:
  clusterIP: None
  ports:
  - name: metrics
    port: 9100
    protocol: TCP
    targetPort: 9100
  selector:
    app: prometheus
    component: node-exporter
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
    component: server
  name: prometheus-server
  namespace: monitoring
spec:
  ports:
  - name: http
    nodePort: 30900
    port: 80
    protocol: TCP
    targetPort: 9090
  selector:
    app: prometheus
    component: server
  type: NodePort
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app: prometheus
    component: alertmanager
  name: prometheus-alertmanager
  namespace: monitoring
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app: prometheus
    component: server
  name: prometheus-server
  namespace: monitoring
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prometheus
    component: alertmanager
  name: prometheus-alertmanager
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
      component: alertmanager
  template:
    metadata:
      labels:
        app: prometheus
        component: alertmanager
    spec:
      containers:
      - args:
        - --config.file=/etc/config/alertmanager.yml
        - --storage.path=/data
        - --cluster.advertise-address=$(POD_IP):6783
        - --web.external-url=https://alertmanager.production.fravega.com
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        image: prom/alertmanager:v0.24.0
        imagePullPolicy: IfNotPresent
        name: prometheus-alertmanager
        ports:
        - containerPort: 9093
        readinessProbe:
          httpGet:
            path: /#/status
            port: 9093
          initialDelaySeconds: 30
          timeoutSeconds: 30
        resources:
          limits:
            cpu: 20m
            memory: 50Mi
          requests:
            cpu: 10m
            memory: 25Mi
        volumeMounts:
        - mountPath: /etc/config
          name: config-volume
        - mountPath: /data
          name: storage-volume
          subPath: ""
      - args:
        - --volume-dir=/etc/config
        - --webhook-url=http://localhost:9093/-/reload
        image: jimmidyson/configmap-reload:v0.6.1
        imagePullPolicy: IfNotPresent
        name: prometheus-alertmanager-configmap-reload
        resources: {}
        volumeMounts:
        - mountPath: /etc/config
          name: config-volume
          readOnly: true
      serviceAccountName: prometheus-alertmanager
      volumes:
      - configMap:
          name: prometheus-alertmanager
        name: config-volume
      - name: storage-volume
        persistentVolumeClaim:
          claimName: prometheus-alertmanager
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prometheus
    component: kube-state-metrics
  name: prometheus-kube-state-metrics
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
      component: kube-state-metrics
  template:
    metadata:
      labels:
        app: prometheus
        component: kube-state-metrics
    spec:
      containers:
      - image: quay.io/coreos/kube-state-metrics:v1.9.8
        imagePullPolicy: IfNotPresent
        name: prometheus-kube-state-metrics
        ports:
        - containerPort: 8080
          name: metrics
        resources:
          limits:
            cpu: 500m
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 100Mi
      serviceAccountName: prometheus-kube-state-metrics
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prometheus
    component: server
    thanos-store-api: "true"
  name: prometheus-server
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
      component: server
  template:
    metadata:
      labels:
        app: prometheus
        app.kubernetes.io/component: prometheus-sidecar
        app.kubernetes.io/instance: thanos-sidecar
        app.kubernetes.io/name: thanos-sidecar
        app.kubernetes.io/version: v0.26.0
        cluster: prometheus-ha
        component: server
        thanos-store-api: "true"
    spec:
      containers:
      - args:
        - sidecar
        - --log.level=debug
        - --prometheus.url=http://localhost:9090
        - --tsdb.path=/data
        - --objstore.config-file=/etc/config/thanos-bucket.yaml
        image: thanosio/thanos:v0.26.0
        name: thanos-sidecar
        ports:
        - containerPort: 10902
          name: http
        - containerPort: 10901
          name: grpc
        resources:
          limits:
            memory: 256Mi
          requests:
            cpu: 0m
            memory: 32Mi
        volumeMounts:
        - mountPath: /etc/config
          name: thanos-config
        - mountPath: /data
          name: storage-volume
          subPath: ""
      - args:
        - --volume-dir=/etc/config
        - --webhook-url=http://127.0.0.1:9090/-/reload
        image: jimmidyson/configmap-reload:v0.6.1
        imagePullPolicy: IfNotPresent
        name: prometheus-server-configmap-reload
        resources: {}
        volumeMounts:
        - mountPath: /etc/config
          name: config-volume
          readOnly: true
      - args:
        - --storage.tsdb.retention=6h
        - --config.file=/etc/config/prometheus.yml
        - --storage.tsdb.path=/data
        - --web.console.libraries=/etc/prometheus/console_libraries
        - --web.console.templates=/etc/prometheus/consoles
        - --web.enable-lifecycle
        - --web.enable-admin-api
        - --storage.tsdb.min-block-duration=2h
        - --storage.tsdb.max-block-duration=2h
        - --web.listen-address=:9090
        - --web.external-url=https://prometheus.production.fravega.com
        - --log.level=debug
        image: prom/prometheus:v2.36.2
        imagePullPolicy: IfNotPresent
        name: prometheus-server
        ports:
        - containerPort: 9090
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 30
          timeoutSeconds: 30
        resources:
          limits:
            cpu: 4
            memory: 60Gi
          requests:
            cpu: 1.5
            memory: 50Gi
        volumeMounts:
        - mountPath: /etc/config
          name: config-volume
        - mountPath: /data
          name: storage-volume
          subPath: ""
      initContainers:
      - command:
        - chown
        - -R
        - 65534:65534
        - /data
        image: busybox:latest
        imagePullPolicy: IfNotPresent
        name: init-chown-data
        resources: {}
        volumeMounts:
        - mountPath: /data
          name: storage-volume
          subPath: ""
      serviceAccountName: prometheus-server
      terminationGracePeriodSeconds: 300
      tolerations:
      - effect: NoSchedule
        key: noderole
        operator: Equal
        value: ram-eater
      volumes:
      - configMap:
          name: prometheus-server
        name: config-volume
      - name: storage-volume
        persistentVolumeClaim:
          claimName: prometheus-server
      - name: thanos-config
        secret:
          secretName: thanos-bucket
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: prometheus
    component: node-exporter
  name: prometheus-node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: prometheus
      component: node-exporter
  template:
    metadata:
      labels:
        app: prometheus
        component: node-exporter
    spec:
      containers:
      - args:
        - --path.procfs=/host/proc
        - --path.sysfs=/host/sys
        image: prom/node-exporter:v1.3.1
        imagePullPolicy: IfNotPresent
        name: prometheus-node-exporter
        ports:
        - containerPort: 9100
          hostPort: 9100
          name: metrics
        resources:
          limits:
            cpu: 500m
            memory: 50Mi
          requests:
            cpu: 100m
            memory: 30Mi
        volumeMounts:
        - mountPath: /host/proc
          name: proc
          readOnly: true
        - mountPath: /host/sys
          name: sys
          readOnly: true
      hostNetwork: true
      hostPID: true
      serviceAccountName: prometheus-node-exporter
      tolerations:
      - effect: NoSchedule
        operator: Exists
      volumes:
      - hostPath:
          path: /proc
        name: proc
      - hostPath:
          path: /sys
        name: sys
  updateStrategy:
    type: RollingUpdate
---
apiVersion: extensions/v1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  labels:
    app: prometheus
    component: alertmanager
  name: prometheus-alertmanager
  namespace: monitoring
spec:
  rules:
  - host: alertmanager.production.fravega.com
    http:
      paths:
      - backend:
          serviceName: prometheus-alertmanager
          servicePort: 80
        path: /
  tls:
  - hosts:
    - alertmanager.production.fravega.com
    secretName: production-fravega-com-tls
---
apiVersion: extensions/v1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  labels:
    app: prometheus
    component: server
  name: prometheus-server
  namespace: monitoring
spec:
  rules:
  - host: prometheus.production.fravega.com
    http:
      paths:
      - backend:
          serviceName: prometheus-server
          servicePort: 80
        path: /
  tls:
  - hosts:
    - prometheus.production.fravega.com
    secretName: production-fravega-com-tls
